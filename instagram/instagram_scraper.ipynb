{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOURCES: \n",
    "When the Entire Page Has Infinite Scroll\n",
    "- https://michaeljsanders.com/2017/05/12/scrapin-and-scrollin.html\n",
    "\n",
    "General Web Scraping Tutorials\n",
    "- https://github.com/pwikstrom/build-a-bot\n",
    "- https://medium.com/@srujana.rao2/scraping-instagram-with-python-using-selenium-and-beautiful-soup-8b72c186a058\n",
    "\n",
    "Remove duplicates from list\n",
    "- https://thispointer.com/python-how-to-remove-duplicates-from-a-list/\n",
    "\n",
    "Get the JSON from the HTML\n",
    "- https://python-forum.io/Thread-ReGex-With-Python?page=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic tips about jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOURCE: https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/\n",
    "\n",
    "- **Esc** will take you into command mode where you can navigate around your notebook with arrow keys.\n",
    "\n",
    "- In command mode:\n",
    "    - **A** to insert a new cell above the current cell, **B** to insert a new cell below.\n",
    "    - **M** to change the current cell to Markdown, **Y** to change it back to code\n",
    "    - **D + D** (press the key twice) to delete the current cell\n",
    "    \n",
    "- **Enter** will take you from command mode back into edit mode for the given cell.\n",
    "- You can also use **Shift + M** to merge multiple cells.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python modules\n",
    "import bs4        # BeautifulSoup4 is a Python package for parsing HTML and XML documents\n",
    "import time       # We need to wait 3 seconds every time that we scroll in instagram\n",
    "import requests   # It allows you to send HTTP requests in Python\n",
    "import re\n",
    "import json \n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver   # A collection of language specific bindings to drive a browser \n",
    "from webdriver_manager.chrome import ChromeDriverManager   # allows to automate the management of the binary drivers \n",
    "                                                           # (e.g. chromedriver, geckodriver...) required by Selenium WebDriver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hashtag/s\n",
    "hashtag='laveganesa'\n",
    "\n",
    "# The bot pretends to be a Chrome browser\n",
    "hdrs = {\"User-Agent\": \"Chrome/78.0\"}\n",
    "\n",
    "# Columns labels\n",
    "colnames = [\"likes_post\", \"datetime\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing duplicates from a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove duplicates (keepping the order of unique elements as it was in the original list)\n",
    "def removeDuplicates(list_elements):\n",
    "    \n",
    "    # Create an empty list to store unique elements\n",
    "    unique_list = []\n",
    "    \n",
    "    # Iterate over the original list and for each element\n",
    "    # add it to uniqueList, if its not already there.\n",
    "    for elem in list_elements:\n",
    "        if elem not in unique_list:\n",
    "            unique_list.append(elem)\n",
    "    \n",
    "    # Return the list of unique elements        \n",
    "    return unique_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scroll and store href of every post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selenium script to scroll to the bottom. We need to wait 3 seconds to the next batch of data to load, then continue scrolling\n",
    "# It will continue to do this until the page stops loading new data.\n",
    "# Meanwhile, we'll store in a list all the href from every post\n",
    "\n",
    "def getHrefInstagram(hashtag):\n",
    "    \n",
    "    # Initialise browser\n",
    "    browser = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    browser.get('https://www.instagram.com/explore/tags/'+hashtag)   \n",
    "\n",
    "    # Scrolling and storing process    \n",
    "    length_page = browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;\")\n",
    "\n",
    "    match=False\n",
    "    list_href=[]\n",
    "\n",
    "    while(match==False):\n",
    "        last_count = length_page\n",
    "        time.sleep(3)\n",
    "        length_page = browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;\")\n",
    "\n",
    "        if last_count==length_page:\n",
    "            match=True\n",
    "\n",
    "        # Grab the source code\n",
    "        source = browser.page_source\n",
    "\n",
    "        # Transform to soup using html.parser (beautify)\n",
    "        soup = bs4.BeautifulSoup(source, \"html.parser\")\n",
    "\n",
    "        # Find all div-tags of class \"v1Nh3 kIKUG  _bz0w\" \n",
    "        links_posts = soup.find_all(\"div\", class_=[\"v1Nh3 kIKUG _bz0w\"]) \n",
    "\n",
    "        # Extract the href from every post\n",
    "        for post in links_posts:\n",
    "\n",
    "            ind_link = post.find(\"a\")\n",
    "            href = \"https://www.instagram.com\" + ind_link.get(\"href\")\n",
    "            list_href +=[href]\n",
    "            \n",
    "    # Remove the duplicates\n",
    "    final_list_href = removeDuplicates(list_href)  \n",
    "    \n",
    "    return final_list_href"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting useful information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infoEveryPost(final_list_href):\n",
    "\n",
    "    list = []\n",
    "    \n",
    "    for post in final_list_href:\n",
    "        \n",
    "        # A. GETTING JSON\n",
    "   \n",
    "        # A.1. Call the url\n",
    "        response_url = requests.get(post, headers=hdrs) \n",
    "\n",
    "        # A.2. Get the JSON from the url. There we'll find the graphql with the data we want\n",
    "        source = response_url.text\n",
    "        data_json = re.findall(r'<script type=\"text/javascript\">window._sharedData = (.*);</script>', source)[0]\n",
    "        data_json = json.loads(data_json)     # it gives back a python dictionary.\n",
    "\n",
    "        # A.3. Let's go to the section we're interested in. Here ['PostPage'][0] contain a list (it has []), \n",
    "        # therefore, we use [0] to get get contented inside this list and continue navigating. \n",
    "        data = data_json['entry_data']['PostPage'][0]['graphql']['shortcode_media']   \n",
    "\n",
    "        # B. GETTING INTERESTING INFORMATION FROM THE JSON\n",
    "\n",
    "        # B.1. Empty item\n",
    "        item_x = []\n",
    "    \n",
    "        # B.2. Likes\n",
    "        likes = data['edge_media_preview_like']['count']\n",
    "        item_x += [likes]\n",
    "        \n",
    "        # B.3. Datetime\n",
    "        from datetime import datetime\n",
    "        temp = data['taken_at_timestamp']\n",
    "        temp = datetime.fromtimestamp(temp)\n",
    "        datetime = temp.strftime(\"%Y-%m-%d %H:%M:%S%z\")\n",
    "        item_x += [datetime]        \n",
    "        \n",
    "        # C. ADD EVERYTHING TO THE LIST\n",
    "        list+= [item_x]\n",
    "    \n",
    "    return pd.DataFrame(list, columns=colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Looking for [chromedriver 78.0.3904.70 win32] driver in cache \n",
      "File found in cache by path [C:\\Users\\saram\\.wdm\\drivers\\chromedriver\\78.0.3904.70\\win32\\chromedriver.exe]\n"
     ]
    }
   ],
   "source": [
    "# Get the href of every post\n",
    "href_everylink = getHrefInstagram(hashtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_info = infoEveryPost(href_everylink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes_post</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>2019-10-18 21:29:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199</td>\n",
       "      <td>2019-03-03 21:56:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>283</td>\n",
       "      <td>2019-03-09 13:00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>261</td>\n",
       "      <td>2017-12-28 17:28:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>2016-07-26 22:55:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>192</td>\n",
       "      <td>2017-07-11 15:08:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>73</td>\n",
       "      <td>2019-09-15 12:04:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>88</td>\n",
       "      <td>2019-09-17 16:01:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>83</td>\n",
       "      <td>2019-10-29 11:44:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>40</td>\n",
       "      <td>2019-11-15 14:01:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>77</td>\n",
       "      <td>2019-11-14 17:53:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>52</td>\n",
       "      <td>2019-11-12 13:03:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>75</td>\n",
       "      <td>2019-11-09 17:08:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>39</td>\n",
       "      <td>2019-11-07 17:16:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>43</td>\n",
       "      <td>2019-11-05 18:32:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>54</td>\n",
       "      <td>2019-10-31 18:29:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-29 21:28:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>113</td>\n",
       "      <td>2019-10-26 19:45:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16</td>\n",
       "      <td>2019-10-24 13:09:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>16</td>\n",
       "      <td>2019-10-23 12:17:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>2019-10-22 23:30:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>55</td>\n",
       "      <td>2019-10-22 17:55:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>58</td>\n",
       "      <td>2019-10-19 12:46:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>28</td>\n",
       "      <td>2019-10-18 12:43:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>18</td>\n",
       "      <td>2019-10-17 11:57:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>69</td>\n",
       "      <td>2019-10-15 17:32:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>63</td>\n",
       "      <td>2019-10-12 13:17:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>2019-10-10 12:53:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>46</td>\n",
       "      <td>2019-10-08 16:41:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>82</td>\n",
       "      <td>2019-10-05 16:32:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>79</td>\n",
       "      <td>2018-07-23 20:00:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>175</td>\n",
       "      <td>2018-07-23 18:01:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>171</td>\n",
       "      <td>2018-07-17 14:47:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>100</td>\n",
       "      <td>2018-07-16 00:18:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>59</td>\n",
       "      <td>2018-07-14 13:10:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>176</td>\n",
       "      <td>2018-07-14 03:14:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>127</td>\n",
       "      <td>2018-07-07 15:16:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>164</td>\n",
       "      <td>2018-07-06 11:23:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>7</td>\n",
       "      <td>2018-04-07 20:54:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>6</td>\n",
       "      <td>2018-04-04 02:33:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>18</td>\n",
       "      <td>2018-03-18 19:21:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>47</td>\n",
       "      <td>2018-01-31 16:49:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>26</td>\n",
       "      <td>2018-01-07 16:39:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>26</td>\n",
       "      <td>2017-09-26 19:22:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>24</td>\n",
       "      <td>2017-09-24 16:33:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>13</td>\n",
       "      <td>2017-08-05 22:14:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>62</td>\n",
       "      <td>2017-06-17 12:55:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>4</td>\n",
       "      <td>2017-04-09 01:44:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>21</td>\n",
       "      <td>2017-03-31 14:50:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>18</td>\n",
       "      <td>2017-03-23 15:16:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>7</td>\n",
       "      <td>2017-03-19 13:41:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>33</td>\n",
       "      <td>2016-12-14 14:48:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>18</td>\n",
       "      <td>2016-10-21 21:15:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>21</td>\n",
       "      <td>2016-10-21 21:15:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>52</td>\n",
       "      <td>2016-10-15 23:39:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>22</td>\n",
       "      <td>2016-09-21 22:14:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>49</td>\n",
       "      <td>2016-08-19 23:06:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>40</td>\n",
       "      <td>2016-08-16 15:09:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>45</td>\n",
       "      <td>2016-07-29 13:13:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>9</td>\n",
       "      <td>2016-07-29 00:49:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     likes_post             datetime\n",
       "0            52  2019-10-18 21:29:50\n",
       "1           199  2019-03-03 21:56:11\n",
       "2           283  2019-03-09 13:00:10\n",
       "3           261  2017-12-28 17:28:35\n",
       "4           105  2016-07-26 22:55:25\n",
       "5           192  2017-07-11 15:08:57\n",
       "6            73  2019-09-15 12:04:37\n",
       "7            88  2019-09-17 16:01:19\n",
       "8            83  2019-10-29 11:44:56\n",
       "9            40  2019-11-15 14:01:57\n",
       "10           77  2019-11-14 17:53:31\n",
       "11           52  2019-11-12 13:03:31\n",
       "12           75  2019-11-09 17:08:05\n",
       "13           39  2019-11-07 17:16:23\n",
       "14           43  2019-11-05 18:32:10\n",
       "15           54  2019-10-31 18:29:52\n",
       "16            4  2019-10-29 21:28:35\n",
       "17          113  2019-10-26 19:45:16\n",
       "18           16  2019-10-24 13:09:54\n",
       "19           16  2019-10-23 12:17:33\n",
       "20           21  2019-10-22 23:30:07\n",
       "21           55  2019-10-22 17:55:52\n",
       "22           58  2019-10-19 12:46:29\n",
       "23           28  2019-10-18 12:43:09\n",
       "24           18  2019-10-17 11:57:59\n",
       "25           69  2019-10-15 17:32:17\n",
       "26           63  2019-10-12 13:17:53\n",
       "27           28  2019-10-10 12:53:32\n",
       "28           46  2019-10-08 16:41:38\n",
       "29           82  2019-10-05 16:32:10\n",
       "..          ...                  ...\n",
       "150          79  2018-07-23 20:00:54\n",
       "151         175  2018-07-23 18:01:50\n",
       "152         171  2018-07-17 14:47:37\n",
       "153         100  2018-07-16 00:18:24\n",
       "154          59  2018-07-14 13:10:30\n",
       "155         176  2018-07-14 03:14:21\n",
       "156         127  2018-07-07 15:16:42\n",
       "157         164  2018-07-06 11:23:42\n",
       "158           7  2018-04-07 20:54:45\n",
       "159           6  2018-04-04 02:33:37\n",
       "160          18  2018-03-18 19:21:20\n",
       "161          47  2018-01-31 16:49:26\n",
       "162          26  2018-01-07 16:39:56\n",
       "163          26  2017-09-26 19:22:11\n",
       "164          24  2017-09-24 16:33:21\n",
       "165          13  2017-08-05 22:14:05\n",
       "166          62  2017-06-17 12:55:13\n",
       "167           4  2017-04-09 01:44:08\n",
       "168          21  2017-03-31 14:50:44\n",
       "169          18  2017-03-23 15:16:12\n",
       "170           7  2017-03-19 13:41:12\n",
       "171          33  2016-12-14 14:48:34\n",
       "172          18  2016-10-21 21:15:57\n",
       "173          21  2016-10-21 21:15:16\n",
       "174          52  2016-10-15 23:39:52\n",
       "175          22  2016-09-21 22:14:20\n",
       "176          49  2016-08-19 23:06:27\n",
       "177          40  2016-08-16 15:09:37\n",
       "178          45  2016-07-29 13:13:25\n",
       "179           9  2016-07-29 00:49:55\n",
       "\n",
       "[180 rows x 2 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.instagram.com/p/B3xXXFehcoV/'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get information from every post\n",
    "first_post = href_everylink[0]\n",
    "first_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Call the url\n",
    "response_url = requests.get(first_post, headers=hdrs) \n",
    "\n",
    "# 2. Get the JSON from the url. There we'll find the graphql with the data we want\n",
    "source = response_url.text\n",
    "data_json = re.findall(r'<script type=\"text/javascript\">window._sharedData = (.*);</script>', source)[0]\n",
    "data_json = json.loads(data_json)     # it gives back a python dictionary.\n",
    "\n",
    "# 3. Let's go to the section we're interested in. Here ['PostPage'][0] contain a list (it has []), \n",
    "# therefore, we use [0] to get get contented inside this list and continue navigating. \n",
    "data = data_json['entry_data']['PostPage'][0]['graphql']['shortcode_media']   \n",
    "\n",
    "# 4. Let's get interesting information!!\n",
    "dt =data['taken_at_timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-10-18 21:29:50'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime = datetime.fromtimestamp(dt)\n",
    "datetime = datetime.strftime(\"%Y-%m-%d %H:%M:%S%z\")\n",
    "datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1571426990"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
